{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "API calls to OMDb for tv_show data.\n",
    "Matt Oliver Taylor Appel\n",
    "\"\"\"\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import omdb\n",
    "import time\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from config import pword, host, user, api_key\n",
    "import Project_1_Webscrape_Functions as web\n",
    "\n",
    "# define omdb client for API calls\n",
    "client=omdb.OMDBClient(apikey=api_key)\n",
    "\n",
    "def omdb_call(tv_title, tv_year):\n",
    "    '''\n",
    "    takes in a key to the api, a title of a tv show, and the year it was released\n",
    "    returns all the imdb data from the omdb API\n",
    "    '''\n",
    "    int_year=int(tv_year)\n",
    "    data = client.get(title=tv_title,  #omdb.OMDBC requires a tv title and a release year\n",
    "                      year=tv_year,\n",
    "                      tomatoes=False) #tomatoes is a parameter that returns rotten tomatoes data\n",
    "    return data\n",
    "\n",
    "def get_tvshow_data(listy,year):\n",
    "    '''\n",
    "    takes in a list of tv shows released in the same year, and a key to the api,\n",
    "    returns a Pandas Data Frame of all the imdb info on the shows\n",
    "    '''\n",
    "    results=[]\n",
    "    for i, show in enumerate(listy):\n",
    "        print(str(i)+show)\n",
    "        results.append(omdb_call(show,year))\n",
    "        time.sleep(.1) #wait 50 milliseconds\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def ship_2_sql(dflisty):\n",
    "    '''\n",
    "    takes in a tv show dataframe then sends the data into AWS tv show database\n",
    "    first doing the merchendise data\n",
    "    '''\n",
    "    cnx = mysql.connector.connect(\n",
    "    #connect to mysql platform        \n",
    "        host =host,\n",
    "        user =user,\n",
    "        passwd = pword\n",
    "        )\n",
    "    cur=cnx.cursor()\n",
    "    cur.execute('USE tv_merch')\n",
    "    for i, show in dflisty.iterrows():\n",
    "        print(i)\n",
    "    # first pass the show data into sql\n",
    "#         cur.execute(\"\"\"INSERT INTO show_data (\n",
    "#                                     show_id,\n",
    "#                                     show_name,\n",
    "#                                     genre,\n",
    "#                                     imdb_rating,\n",
    "#                                     imdb_votes,\n",
    "#                                     metascore,\n",
    "#                                     released,\n",
    "#                                     rated\n",
    "#                                     ) \n",
    "#         VALUES (\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",\"{}\"\n",
    "#         )\"\"\".format(show['imdb_id'],\n",
    "#                     show['title'],\n",
    "#                     show['genre'],\n",
    "#                     show['imdb_rating'],\n",
    "#                     show['imdb_votes'],\n",
    "#                     show['metascore'],\n",
    "#                     show['year'],\n",
    "#                     show['rated']))\n",
    "#     then pass the sales data into sql\n",
    "        cur.execute(\"\"\"INSERT INTO merch_data (\n",
    "                                    show_id,\n",
    "                                    etsy,\n",
    "                                    ebay,\n",
    "                                    bonanza,\n",
    "                                    show_name\n",
    "                                    ) \n",
    "        VALUES ({},{},{},{},{}\n",
    "        )\"\"\".format(show['imdb_id'],\n",
    "                    show['etsy'],\n",
    "                    show['ebay'],\n",
    "                    show['bonanza'],\n",
    "                    show['title']))\n",
    "    cnx.commit()\n",
    "    cur.close()\n",
    "    cnx.close()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "'''\n",
    "#test code\n",
    "show_name = str(input('Name: \\n'))\n",
    "show_year = str(input('Year: \\n'))\n",
    "\n",
    "df = pd.DataFrame(omdb_call( api_key, show_name,show_year))\n",
    "df.head(1)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#brings all programs together, creating cumulative dataframe and saving to SQL\n",
    "\n",
    "\n",
    "shows_by_year=web.tv_list_makr()\n",
    "imdb_data_by_year=[]\n",
    "# for i, year in enumerate(shows_by_year[9:]):\n",
    "#     imdb_data_by_year.append(get_tvshow_data(year,2019+i))\n",
    "frames=[                imdb_data_by_year[1],\n",
    "                        imdb_data_by_year[2],\n",
    "                        imdb_data_by_year[3],\n",
    "                        imdb_data_by_year[4],\n",
    "                        imdb_data_by_year[5],\n",
    "                        imdb_data_by_year[6],\n",
    "                        imdb_data_by_year[7],\n",
    "                        imdb_data_by_year[8],\n",
    "                        imdb_data_by_year[9],\n",
    "                        imdb_data_by_year[10]]\n",
    "show_data=pd.concat(frames)\n",
    "show_data['year']\n",
    "\n",
    "\n",
    "\n",
    "#quick look for element in merch data \n",
    "\n",
    "data.drop([86],inplace=True) #unwanted column\n",
    "j=3\n",
    "print(data['title'][j])\n",
    "print(bonanza[j]['result'][0]['Results'])\n",
    "print(ebay[j]['result'][0]['Results'])\n",
    "print(etsy[j]['result'][0]['Results'])\n",
    "\n",
    "\n",
    "\n",
    "#import ebay, etsy and bonanza data into show dataframe\n",
    "\n",
    "result=lambda x:x['result'][0]['Results']\n",
    "data['ebay']=[result(ebay[i]) for i in range(len(ebay))]\n",
    "data['etsy']=[result(etsy[i]) for i in range(len(etsy))]\n",
    "data['bonanza']=[result(bonanza[i]) for i in range(len(bonanza))]\n",
    "\n",
    "\n",
    "#dropping unwanted columns\n",
    "\n",
    "drop_me=['awards',\n",
    "         'actors',\n",
    "         'box_office',\n",
    "         'country',\n",
    "         'director',\n",
    "         'dvd',\n",
    "         'language',\n",
    "         'metascore',\n",
    "         'plot',\n",
    "         'poster',\n",
    "         'production',\n",
    "         'response',\n",
    "         'total_seasons',\n",
    "         'ratings',\n",
    "         'type',\n",
    "         'website',\n",
    "         'writer']\n",
    "data.drop(drop_me, axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#save dataframe\n",
    "'''\n",
    "data=pd.read_csv('tv_show_data.csv')\n",
    "'''\n",
    "\n",
    "# #data exploration tool\n",
    "# gimme= ['title','ebay','etsy','bonanza','imdb_votes','imdb_rating','year']\n",
    "# data[gimme].sort_values(['ebay'],ascending=False)[200:250]\n",
    "    \n",
    "# #cleaning etsy data\n",
    "# etsy_filter=lambda x,y,z: np.NaN if (x>100)and(z<=4)and(y<10) else x\n",
    "# etsy_high_clip=lambda x: 0 if x>40000 else x\n",
    "# data['etsy2']=[etsy_medium_clip(data['etsy'][i],data['bonanza']\n",
    "#[i],data['ebay'][i]) for i in range(len(data['etsy']))]\n",
    "\n",
    "# #change column type\n",
    "# data['imdb_votes']=data['imdb_votes'].map(lambda x: x.replace(',','')if type(x)==str else x)\n",
    "# data['imdb_votes']=data['imdb_votes'].astype(dtype='float64',errors='raise')\n",
    "\n",
    "#scale the review data for comparison\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "temp_scaled = scaler.fit(temp)\n",
    "scaled=pd.DataFrame(temp_scaled.transform(temp), columns = ['ebay','etsy2','bonanza','imdb_votes'])\n",
    "\n",
    "\n",
    "\n",
    "#heat plot of correlation\n",
    "corr_data=scaled[['ebay','etsy2','bonanza','scaled_total','imdb_votes']]\n",
    "corr_data['imdb_rating']=data['imdb_rating']\n",
    "pearsoncorr_scaled= corr_data.corr()\n",
    "sb.heatmap(pearsoncorr_scaled, \n",
    "            xticklabels=pearsoncorr_scaled.columns,\n",
    "            yticklabels=pearsoncorr_scaled.columns,\n",
    "            cmap='RdBu_r',\n",
    "            annot=True,\n",
    "            linewidth=0.5)\n",
    "\n",
    "\n",
    "\n",
    "# create table with both scaled and normal data including genre data\n",
    "genres=[]\n",
    "\n",
    "for i, show in data.iterrows():\n",
    "    if type(data['genre'][i])==list:\n",
    "        for j in range(len(data['genre'][i])):\n",
    "#             data['genre'][i][j]=data['genre'][i][j].strip()\n",
    "            stuff={'imdb_id':data['imdb_id'][i],\n",
    "                   'genre':data['genre'][i][j],\n",
    "                   'rating':data['imdb_rating'][i],\n",
    "                   'votes':data['imdb_votes'][i],\n",
    "                   'etsy2':data['etsy2'][i]/102.1,\n",
    "                   'ebay':data['ebay'][i]/292.4,\n",
    "                   'unscaled_total':data['unscaled_total'][i],\n",
    "                   'bonanza':data['bonanza'][i]/4.851,\n",
    "                   's_etsy2':scaled['etsy2'][i],\n",
    "                   's_ebay':scaled['ebay'][i],\n",
    "                   's_bonanza':scaled['bonanza'][i],\n",
    "                   's_votes':scaled['imdb_votes'][i],\n",
    "                   'scaled_total':data['scaled_total'][i],\n",
    "                   'total_div_votes':(data['unscaled_total'][i])/data['imdb_votes'][i]\n",
    "                  }\n",
    "            \n",
    "            genres.append(stuff)\n",
    "            print(i,j,data['genre'][i][j]) \n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "#plot scaled genre data\n",
    "genres_data=pd.DataFrame(genres)\n",
    "genre_plot_data=genres_data.groupby(['genre']).mean().sort_values(['scaled_total'],ascending=False)\n",
    "genre_plot_data.plot.bar(y=['scaled_total','s_votes'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
